{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running an application\n",
    "\n",
    "Now that we have developed our machine learning model in notebooks, we want to deploy it as a service. The purpose is to allow data science exploration to easily transition into deployed services and applications on the OpenShift platform.  After saving this project to git, it can be built on the OpenShift platform to serve models.\n",
    "\n",
    "\n",
    "There are a lot of files in this folder. We will only need to edit the noteboks, but here's insight into what each of these files do: \n",
    "\n",
    "### Project Organization\n",
    "```\n",
    ".\n",
    "├── README.md\n",
    "├── LICENSE\n",
    "├── requirements.txt        <- Used to install packages for s2i application\n",
    "├── 0_start_here.ipynb      <- Instructional notebook\n",
    "├── 1_run_flask.ipynb       <- Notebook for running flask locally to test\n",
    "├── 2_test_flask.ipynb      <- Notebook for testing flask requests\n",
    "├── .gitignore              <- standard python gitignore\n",
    "├── .s2i                    <- hidden folder for advanced s2i configuration\n",
    "│   └── environment         <- s2i environment settings\n",
    "├── gunicorn_config.py      <- configuration for gunicorn when run in OpenShift\n",
    "├── prediction.py           <- the predict function called from Flask\n",
    "└── wsgi.py                 <- basic Flask application\n",
    "```\n",
    "\n",
    "We will use a source to image build, also known as s2i, to deploy the model service, but first let's practice running the service in a notebook: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "id": "KUu4vOt5zI9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Flask\n",
      "  Downloading Flask-2.1.1-py3-none-any.whl (95 kB)\n",
      "     |████████████████████████████████| 95 kB 5.1 MB/s             \n",
      "\u001b[?25hCollecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "     |████████████████████████████████| 79 kB 26.6 MB/s            \n",
      "\u001b[?25hCollecting numpy==1.18.1\n",
      "  Downloading numpy-1.18.1-cp38-cp38-manylinux1_x86_64.whl (20.6 MB)\n",
      "     |████████████████████████████████| 20.6 MB 34.6 MB/s            1��██████▏            | 12.4 MB 34.6 MB/s eta 0:00:01|██████████████████████████      | 16.7 MB 34.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
      "     |████████████████████████████████| 26.0 MB 70.4 MB/s            �██████████▋               | 13.5 MB 70.4 MB/s eta 0:00:01███████████████████████▊     | 21.7 MB 70.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==1.0.3\n",
      "  Downloading pandas-1.0.3-cp38-cp38-manylinux1_x86_64.whl (10.0 MB)\n",
      "     |████████████████████████████████| 10.0 MB 39.7 MB/s            █▌                             | 768 kB 39.7 MB/s eta 0:00:01�████████████▎        | 7.2 MB 39.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn==0.22.1\n",
      "  Downloading scikit_learn-0.22.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
      "     |████████████████████████████████| 7.0 MB 45.7 MB/s             1.1 MB 45.7 MB/s eta 0:00:016.3 MB 45.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow==0.16.0\n",
      "  Downloading pyarrow-0.16.0-cp38-cp38-manylinux2014_x86_64.whl (63.2 MB)\n",
      "     |████████████████████████████████| 63.2 MB 61.9 MB/s            MB 61.9 MB/s eta 0:00:01019 MB/s eta 0:00:01�██████████▉               | 33.1 MB 61.9 MB/s eta 0:00:01MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle==1.5.0 in /opt/app-root/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/app-root/lib/python3.8/site-packages (from pandas==1.0.3->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/app-root/lib/python3.8/site-packages (from pandas==1.0.3->-r requirements.txt (line 5)) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/app-root/lib/python3.8/site-packages (from scikit-learn==0.22.1->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: six>=1.0.0 in /opt/app-root/lib/python3.8/site-packages (from pyarrow==0.16.0->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: click>=8.0 in /opt/app-root/lib/python3.8/site-packages (from Flask->-r requirements.txt (line 1)) (8.0.3)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.1.1-py3-none-any.whl (224 kB)\n",
      "     |████████████████████████████████| 224 kB 64.5 MB/s            \n",
      "\u001b[?25hCollecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/app-root/lib/python3.8/site-packages (from Flask->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /opt/app-root/lib/python3.8/site-packages (from Flask->-r requirements.txt (line 1)) (4.10.0)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/app-root/lib/python3.8/site-packages (from gunicorn->-r requirements.txt (line 2)) (60.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/app-root/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->Flask->-r requirements.txt (line 1)) (3.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.8/site-packages (from Jinja2>=3.0->Flask->-r requirements.txt (line 1)) (2.0.1)\n",
      "Installing collected packages: numpy, Werkzeug, scipy, itsdangerous, scikit-learn, pyarrow, pandas, gunicorn, Flask\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.0\n",
      "    Uninstalling numpy-1.21.0:\n",
      "      Successfully uninstalled numpy-1.21.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.1\n",
      "    Uninstalling scipy-1.7.1:\n",
      "      Successfully uninstalled scipy-1.7.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.1\n",
      "    Uninstalling scikit-learn-0.24.1:\n",
      "      Successfully uninstalled scikit-learn-0.24.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 0.17.0\n",
      "    Uninstalling pyarrow-0.17.0:\n",
      "      Successfully uninstalled pyarrow-0.17.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.2\n",
      "    Uninstalling pandas-1.3.2:\n",
      "      Successfully uninstalled pandas-1.3.2\n",
      "Successfully installed Flask-2.1.1 Werkzeug-2.1.1 gunicorn-20.1.0 itsdangerous-2.1.2 numpy-1.18.1 pandas-1.0.3 pyarrow-0.16.0 scikit-learn-0.22.1 scipy-1.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "Experiment with data and create your prediction function.  Create any serialized models needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle as cp\n",
    "import pandas as pd\n",
    "\n",
    "pipeline = cp.load(open('pipeline.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(args_dict):\n",
    "\n",
    "    d = {'timestamp':0, 'label':0, 'user_id': args_dict.get('user_id'), 'amount': args_dict.get('amount'), 'merchant_id': args_dict.get('merchant_id'), 'trans_type': args_dict.get('trans_type'), 'foreign': args_dict.get('foreign'), 'interarrival': args_dict.get('interarrival')}\n",
    "    \n",
    "    df = pd.DataFrame(d, index=[0])\n",
    "    prediction = pipeline.predict(df)[0]\n",
    "\n",
    "    return {'prediction': prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 'legitimate'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_req = {\"user_id\": 1698, \"amount\": 7915, \"merchant_id\": 22.37, \"trans_type\": \"contactless\", \"foreign\": \"False\", \"interarrival\": 9609}\n",
    "\n",
    "predict(my_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Predict Function\n",
    "\n",
    "Now that we are certain our prediction function is working, we can go ahead and add it to the prediction.py file. We've already done this for you, but go take a look and make sure you see what's happening. \n",
    "\n",
    "Also, make sure `requirements.txt` is updated with any additional packages you've used and need for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 'legitimate'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prediction import predict\n",
    "\n",
    "\n",
    "my_req = {\"user_id\": 1698, \"amount\": 7915, \"merchant_id\": 22.37, \"trans_type\": \"contactless\", \"foreign\": \"False\", \"interarrival\": 9609}\n",
    "\n",
    "predict(my_req)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to get a prediction of fraud\n",
    "\n",
    "Now, try it again, but this time, change the values until the prediction returns **fraud** instead of **legitimate**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 'legitimate'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_req = {\"user_id\": 9999, \n",
    "             \"amount\": 9999, \n",
    "             \"merchant_id\": 99999, \n",
    "             \"trans_type\": \"contactless\", \n",
    "             \"foreign\": \"False\", \n",
    "             \"interarrival\": 1}\n",
    "\n",
    "predict(other_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Object detection",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
